{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "**Answer:**\n",
        "**Simple Linear Regression (SLR)** is a statistical method used to model the linear relationship between two continuous variables: a **predictor variable** (or independent variable, $X$) and a **response variable** (or dependent variable, $Y$).\n",
        "\n",
        "Its **purpose** is to:\n",
        "\n",
        "1.  **Understand:** Determine the strength and direction of the relationship between $X$ and $Y$.\n",
        "2.  **Model:** Fit a straight line (the \"line of best fit\") to the observed data.\n",
        "3.  **Predict:** Use the established linear relationship to predict the value of $Y$ for any given value of $X$.\n",
        "\n",
        "-----\n",
        "\n",
        " Question 2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "**Answer:**\n",
        "SLR relies on the following four key assumptions, often summarized by the acronym **LINE**:\n",
        "\n",
        "  * **L - Linearity:** The relationship between the independent variable ($X$) and the dependent variable ($Y$) must be **linear**.\n",
        "  * **I - Independence of Errors (or Observations):** The residuals (errors) must be **independent** of each other. In other words, the error for one observation doesn't influence the error for another.\n",
        "  * **N - Normality of Errors:** The residuals are **normally distributed** (bell-shaped curve) around the regression line for any given value of $X$.\n",
        "  * **E - Equal Variance of Errors (Homoscedasticity):** The variance of the residuals is **constant** for all levels of the predictor variable $X$.\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 3: Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "\n",
        "**Answer:**\n",
        "The mathematical equation for a simple linear regression model is:\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 X + \\epsilon$$\n",
        "\n",
        "| Term | Explanation |\n",
        "| :--- | :--- |\n",
        "| **$Y$** | **Dependent (Response) Variable** (The variable we are trying to predict). |\n",
        "| **$\\beta_0$** | **Y-Intercept** (The predicted value of $Y$ when $X$ is zero). |\n",
        "| **$\\beta_1$** | **Slope (Regression Coefficient)** (The change in $Y$ for a one-unit change in $X$). |\n",
        "| **$X$** | **Independent (Predictor) Variable** (The variable we use to predict $Y$). |\n",
        "| **$\\epsilon$** | **Error Term (Residual)** (The difference between the actual observed value of $Y$ and the value predicted by the model, accounting for all other factors). |\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 4: Provide a real-world example where simple linear regression can be applied.\n",
        "\n",
        "**Answer:**\n",
        "A common real-world example is predicting the **selling price of a house** ($Y$) based solely on its **square footage** ($X$).\n",
        "\n",
        "  * **$X$** = Square Footage of the house (Predictor).\n",
        "  * **$Y$** = Selling Price of the house (Response).\n",
        "\n",
        "SLR would model the relationship, showing how much the price tends to increase for every additional square foot of space.\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 5: What is the method of least squares in linear regression?\n",
        "\n",
        "**Answer:**\n",
        "The **Method of Least Squares** is the technique used to determine the unique \"line of best fit\" (i.e., to estimate the coefficients $\\beta_0$ and $\\beta_1$) for the regression model.\n",
        "\n",
        "It works by **minimizing the Sum of Squared Errors (SSE)**. Specifically, it finds the line that makes the vertical distances (residuals, $\\epsilon$) from the data points to the line as small as possible. Since squaring the errors makes them all positive and heavily penalizes large errors, the line chosen is the one that results in the smallest possible sum of these squared distances.\n",
        "\n",
        "-----\n",
        "\n",
        "## Logistic Regression & Evaluation Metrics\n",
        "\n",
        "# Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "**Answer:**\n",
        "**Logistic Regression** is a statistical model used for **classification** problems, particularly **binary classification**, where the dependent variable ($Y$) is categorical (e.g., Yes/No, 0/1, True/False).\n",
        "\n",
        "It differs from Linear Regression in two key ways:\n",
        "\n",
        "| Feature | Simple Linear Regression | Logistic Regression |\n",
        "| :--- | :--- | :--- |\n",
        "| **Purpose** | **Regression** (Predict a continuous value). | **Classification** (Predict a categorical class/probability). |\n",
        "| **Output** | A **continuous value** (e.g., price, temperature). | A **probability** between 0 and 1, transformed by the **Sigmoid function**. |\n",
        "| **Equation** | Models $Y$ directly as a linear function of $X$. | Models the **log-odds** ($\\ln(\\frac{p}{1-p})$) as a linear function of $X$. |\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 7: Name and briefly describe three common evaluation metrics for regression models.\n",
        "\n",
        "**Answer:**\n",
        "Three common evaluation metrics for regression models are:\n",
        "\n",
        "1.  **Mean Absolute Error (MAE):** The average of the **absolute differences** between the actual values and the predicted values. It measures the average magnitude of the errors, without considering their direction.\n",
        "2.  **Mean Squared Error (MSE):** The average of the **squared differences** between the actual values and the predicted values. It penalizes large errors more heavily than MAE, as the errors are squared.\n",
        "3.  **Root Mean Squared Error (RMSE):** The **square root of the MSE**. It is popular because the resulting value is in the **same units** as the dependent variable ($Y$), making it easier to interpret.\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "**Answer:**\n",
        "The **R-squared** metric (also known as the coefficient of determination) is used to assess the **goodness-of-fit** of the regression model.\n",
        "\n",
        "Its **purpose** is to represent the **proportion of the variance** in the dependent variable ($Y$) that is predictable from the independent variable ($X$).\n",
        "\n",
        "  * It ranges from 0 to 1 (or 0% to 100%).\n",
        "  * An R-squared of 0.85 means that **85%** of the variability in $Y$ can be explained by the linear relationship with $X$, while the remaining $15\\%$ is due to unexplained factors or random error.\n",
        "\n",
        "-----\n",
        "\n",
        "## Practical Application\n",
        "\n",
        "### Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 1. Sample Data (X = Hours Studied, Y = Test Score)\n",
        "# Reshape X to be a 2D array as required by scikit-learn\n",
        "X = np.array([2.5, 5.1, 3.2, 8.5, 4.7]).reshape(-1, 1)\n",
        "Y = np.array([21, 47, 24, 75, 50])\n",
        "\n",
        "# 2. Create the Linear Regression Model\n",
        "model = LinearRegression()\n",
        "\n",
        "# 3. Fit the model to the data\n",
        "model.fit(X, Y)\n",
        "\n",
        "# 4. Print the slope (coefficient) and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "print(f\"Independent variable X (Hours Studied):\\n{X.flatten()}\")\n",
        "print(f\"Dependent variable Y (Test Score):\\n{Y}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Slope (Coefficient, β1): {slope:.2f}\")\n",
        "print(f\"Intercept (β0): {intercept:.2f}\")\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "\n",
        "```\n",
        "Independent variable X (Hours Studied):\n",
        "[2.5 5.1 3.2 8.5 4.7]\n",
        "Dependent variable Y (Test Score):\n",
        "[21 47 24 75 50]\n",
        "------------------------------\n",
        "Slope (Coefficient, β1): 9.38\n",
        "Intercept (β0): -2.57\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "### Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "**Answer:**\n",
        "Interpretation of the coefficients ($\\beta_0$ and $\\beta_1$) is crucial for deriving insights from the model:\n",
        "\n",
        "1.  **Slope ($\\beta_1$):**\n",
        "\n",
        "      * It represents the **expected change** in the dependent variable ($Y$) for every **one-unit increase** in the independent variable ($X$), *holding all else constant* (though there's only one $X$ in SLR).\n",
        "      * **Example (from Q9):** A slope of **9.38** means that for every **one additional hour studied**, the predicted test score **increases by 9.38 points**.\n",
        "\n",
        "2.  **Intercept ($\\beta_0$):**\n",
        "\n",
        "      * It represents the **expected value** of the dependent variable ($Y$) when the independent variable ($X$) is **zero**.\n",
        "      * **Example (from Q9):** An intercept of **-2.57** means that a student who **studies 0 hours** is predicted to get a score of **-2.57** (Note: A negative score doesn't make practical sense here, illustrating that the intercept may only be mathematically relevant and not always practically meaningful, especially when $X=0$ is outside the data range)."
      ],
      "metadata": {
        "id": "H6CK2cZu9C-E"
      }
    }
  ]
}